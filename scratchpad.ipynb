{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sqlalchemy\n",
    "#import mysql.connector as msql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate on all csv files\n",
    "load into pandas as df\n",
    "use sqlalchemy engine and pandas to_sql\n",
    "to_sql(if_exists= 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded Affiliation\n",
      "loaded Assessment\n",
      "loaded AssessmentQuestions\n",
      "loaded AssessmentResults\n",
      "loaded Client\n",
      "loaded CurrentLivingSituation\n",
      "loaded Disabilities\n",
      "loaded EmploymentEducation\n",
      "loaded Enrollment\n",
      "loaded EnrollmentCoC\n",
      "loaded Event\n",
      "loaded Exit\n",
      "loaded Export\n",
      "loaded Funder\n",
      "loaded HealthAndDV\n",
      "loaded IncomeBenefits\n",
      "loaded Inventory\n",
      "loaded Organization\n",
      "loaded Project\n",
      "loaded ProjectCoC\n",
      "loaded Services\n",
      "loaded User\n",
      "loaded YouthEducationStatus\n"
     ]
    }
   ],
   "source": [
    "# Assign directory\n",
    "directory = 'C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files'\n",
    "\n",
    "# Iterate over csv files. Create dataframes and load with engine.\n",
    "files = Path(directory).glob('*.csv')\n",
    "\n",
    "for file in files:\n",
    "    bf_df = pd.read_csv(file,index_col=False)\n",
    "    # gets file name from full file path\n",
    "    file_name = Path(file).stem\n",
    "    # Insert DataFrame into db. If table exists -> replace table\n",
    "        # credentials should be environmental variables regarding best practice.\n",
    "        # If engine is not passed in the loop to_sql() will timeout.\n",
    "    engine = sqlalchemy.create_engine(\"mysql+mysqlconnector://perkins:perkins@45.79.53.180:3306/bitfocus_perkins\")\n",
    "    bf_df.to_sql(file_name, con= engine,chunksize= 1000, method= 'multi', if_exists= 'replace',index=False)\n",
    "    print(f\"loaded {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlalchemy engine\n",
    "# credentials should be environmental variables in best practice.\n",
    "engine_url = \"mysql+mysqlconnector://perkins:perkins@45.79.53.180:3306/bitfocus_perkins\"\n",
    "engine = sqlalchemy.create_engine(engine_url)\n",
    "\n",
    "# Assign directory\n",
    "directory = 'C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files'\n",
    "\n",
    "# Iterate over csv files. Create dataframes and load with engine.\n",
    "files = Path(directory).glob('*.csv')\n",
    "\n",
    "for file in files:\n",
    "    bf_df = pd.read_csv(file,index_col=False)\n",
    "    # gets file name from full file path\n",
    "    file_name = Path(file).stem\n",
    "    # Insert DataFrame into db. If table exists -> replace table\n",
    "    bf_df.to_sql(file_name, con= engine,chunksize= 200, method= 'multi', if_exists= 'replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlalchemy engine\n",
    "# credentials should be environmental variables in best practice.\n",
    "engine_url = \"mariadb+mariadbconnector://perkins:perkins@45.79.53.180:3306/bitfocus_perkins\" \n",
    "engine = sqlalchemy.create_engine(engine_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_df = pd.read_csv('C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files\\\\Disabilities.csv',index_col=False)\n",
    "\n",
    "bf_df.to_sql('disabilities', con= engine, if_exists= 'replace',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files'\n",
    "\n",
    "#os.path.split()\n",
    "files = Path(directory).glob('*.csv')\n",
    "for file in files:\n",
    "    file_name = Path(file).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign directory\n",
    "directory = 'C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files'\n",
    "\n",
    "\n",
    "# Iterate over csv files. Create dataframes and load with engine.\n",
    "files = Path(directory).glob('*.csv')\n",
    "for file in files:\n",
    "    bf_df = pd.read_csv(file,index_col=False)\n",
    "    # file name\n",
    "    file_name = Path(file).stem\n",
    "    # Insert DataFrame into db. If table exists -> replace table\n",
    "    engine = sqlalchemy.create_engine(\"mysql+mysqlconnector://perkins:perkins@45.79.53.180:3306/bitfocus_perkins\")\n",
    "    bf_df.to_sql(file_name, con= engine,chunksize= 1000, method= 'multi', if_exists= 'replace',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using mariadb cursor.execute create and insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MariaDB\n",
    "conn = mariadb.connect(\n",
    "    user=\"perkins\",\n",
    "    password=\"perkins\",\n",
    "    host=\"45.79.53.180\",\n",
    "    port=3306,\n",
    "    database=\"bitfocus_perkins\"\n",
    ")\n",
    "\n",
    "\n",
    "# Get Cursor\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_data = pd.read_csv(\n",
    "    'C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files\\\\Disabilities.csv', index_col=False, delimiter=',')\n",
    "\n",
    "try:\n",
    "    conn = mariadb.connect(host='localhost',\n",
    "                           port=3306,\n",
    "                           database='bitfocus',\n",
    "                           user='root',\n",
    "                           password='root@123')\n",
    "    if conn.is_connected():\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(\"You're connected to database: \", record)\n",
    "        cursor.execute('DROP TABLE IF EXISTS disability_data;')\n",
    "        print('Creating table....')\n",
    "# Update CREATE TABLE statement\n",
    "        cursor.execute(\"CREATE TABLE Disabilities(\n",
    "            DisabilitiesID VARCHAR(50),\n",
    "            EnrollmentID INTEGER,\n",
    "            PersonalID INTEGER,\n",
    "            InformationDate VARCHAR(50),\n",
    "            DisabilityType INTEGER,\n",
    "            DisabilityResponse INTEGER,\n",
    "            IndefiniteAndImpairs INTEGER,\n",
    "            TCellCountAvailable VARCHAR(50),\n",
    "            TCellCount VARCHAR(50),\n",
    "            TCellSource VARCHAR(50),\n",
    "            ViralLoadAvailable VARCHAR(50),\n",
    "            ViralLoad VARCHAR(50),\n",
    "            ViralLoadSource VARCHAR(50),\n",
    "            AntiRetroviral VARCHAR(50),\n",
    "            DataCollectionStage INTEGER,\n",
    "            DateCreated VARCHAR(50),\n",
    "            DateUpdated VARCHAR(50),\n",
    "            UserID INTEGER,\n",
    "            DateDeleted VARCHAR(50),\n",
    "            ExportID INTEGER)\")\n",
    "        print(\"Table is created....\")\n",
    "        # INSERT INTO by df row\n",
    "        for i, row in disability_data.iterrows():\n",
    "            # %S is string values per. Needs to match number of columns\n",
    "            sql = \"INSERT INTO bitfocus.disability_data VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cursor.execute(sql, tuple(row))\n",
    "            print(\"Record inserted\")\n",
    "            conn.commit()\n",
    "except:\n",
    "    print(\"Error while connecting to database\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses csv and mariadb. Assumes table exists in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import mariadb\n",
    "\n",
    "conn = mariadb.connect(host='localhost',\n",
    "                       port=3306,\n",
    "                       database='bitfocus',\n",
    "                       user='root',\n",
    "                       password='root@123')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "disability_data = csv.reader(file('C:\\\\Users\\\\Landon\\\\Python Projects\\\\bitfocus\\\\files\\\\Disabilities.csv'))\n",
    "for row in disability_data:\n",
    "    sql = \"INSERT INTO bitfocus.disability_data VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "            cursor.execute(sql, tuple(row))\n",
    "    cursor.execute\n",
    "# close the connection to the database.\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "print \"Done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "cursor.execute(\"CREATE TABLE Disabilities(\n",
    "    DisabilitiesID VARCHAR(50),\n",
    "    EnrollmentID INTEGER,\n",
    "    PersonalID INTEGER,\n",
    "    InformationDate VARCHAR(50),\n",
    "    DisabilityType INTEGER,\n",
    "    DisabilityResponse INTEGER,\n",
    "    IndefiniteAndImpairs INTEGER,\n",
    "    TCellCountAvailable VARCHAR(50),\n",
    "    TCellCount VARCHAR(50),\n",
    "    TCellSource VARCHAR(50),\n",
    "    ViralLoadAvailable VARCHAR(50),\n",
    "    ViralLoad VARCHAR(50),\n",
    "    ViralLoadSource VARCHAR(50),\n",
    "    AntiRetroviral VARCHAR(50),\n",
    "    DataCollectionStage INTEGER,\n",
    "    DateCreated VARCHAR(50),\n",
    "    DateUpdated VARCHAR(50),\n",
    "    UserID INTEGER,\n",
    "    DateDeleted VARCHAR(50),\n",
    "    ExportID INTEGER)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load table\n",
    "cursor.execute(\n",
    "    \"INSERT INTO employees (first_name,last_name) VALUES (?, ?)\", \n",
    "    (first_name, last_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
